{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4096f3-4edb-4dce-9bce-cfac6e3c7b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b853df-f32c-4a04-bd38-1e32eabbd483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[hf_xet] in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (2026.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\envs\\nlp-gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"huggingface_hub[hf_xet]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c172b664-271d-444e-802a-d27d83291772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\nlp-gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Conda\\envs\\nlp-gpu\\Lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624f9c82-5eb6-4c1e-8666-f8bd61ce5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ю Юлия А. Цвет товара: синий, Российский разме...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>С Сергей Ш. Цвет товара: синий, Российский раз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Цвет товара: серый, Российский размер: 50, Раз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ф Флера М. Цвет товара: белый, Российский разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>С Сергей Т. изменен Цвет товара: черный, Росси...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Ю Юлия А. Цвет товара: синий, Российский разме...\n",
       "1  С Сергей Ш. Цвет товара: синий, Российский раз...\n",
       "2  Цвет товара: серый, Российский размер: 50, Раз...\n",
       "3  Ф Флера М. Цвет товара: белый, Российский разм...\n",
       "4  С Сергей Т. изменен Цвет товара: черный, Росси..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH = \"datasets/reviews.xlsx\"\n",
    "OUTPUT_PATH = \"datasets/reviews_out.xlsx\"\n",
    "\n",
    "df = pd.read_excel(INPUT_PATH)\n",
    "\n",
    "if df.shape[1] == 1:\n",
    "    df.columns = [\"review\"]\n",
    "\n",
    "REVIEW_COLUMN = \"review\"\n",
    "if REVIEW_COLUMN not in df.columns:\n",
    "    REVIEW_COLUMN = df.columns[0]\n",
    "\n",
    "df[REVIEW_COLUMN] = df[REVIEW_COLUMN].astype(str)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a415776c-9b73-42fa-94f4-8d7716b5c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\nlp-gpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\hf_cache\\transformers\\models--Qwen--Qwen2.5-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 2 files: 100%|█████████████████████████████████████████████████████████████████| 2/2 [07:41<00:00, 230.73s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.34s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"cuda:\", torch.cuda.is_available())\n",
    "print(\"model device:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2862a43-6b3a-4a6b-9418-19851f619c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты аналитик отзывов маркетплейса. \"\n",
    "    \"Выдай строго JSON без пояснений и без markdown. \"\n",
    "    \"Поля: sentiment (positive|neutral|negative), aspect (quality|price|delivery|service|other), summary (коротко 5-15 слов). \"\n",
    "    \"Игнорируй мусор, артикулы, случайные символы, обрывки.\"\n",
    ")\n",
    "\n",
    "def _extract_json(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {\"sentiment\": \"neutral\", \"aspect\": \"other\", \"summary\": \"\"}\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return {\"sentiment\": \"neutral\", \"aspect\": \"other\", \"summary\": \"\"}\n",
    "\n",
    "@torch.inference_mode()\n",
    "def analyze_review(review: str) -> dict:\n",
    "    review = str(review).strip()\n",
    "    if not review:\n",
    "        return {\"sentiment\": \"neutral\", \"aspect\": \"other\", \"summary\": \"\"}\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": review[:4000]},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    gen = tokenizer.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "    data = _extract_json(gen)\n",
    "\n",
    "    sentiment = data.get(\"sentiment\", \"neutral\")\n",
    "    aspect = data.get(\"aspect\", \"other\")\n",
    "    summary = data.get(\"summary\", \"\")\n",
    "\n",
    "    if sentiment not in {\"positive\", \"neutral\", \"negative\"}:\n",
    "        sentiment = \"neutral\"\n",
    "    if aspect not in {\"quality\", \"price\", \"delivery\", \"service\", \"other\"}:\n",
    "        aspect = \"other\"\n",
    "    if not isinstance(summary, str):\n",
    "        summary = str(summary)\n",
    "\n",
    "    return {\"sentiment\": sentiment, \"aspect\": aspect, \"summary\": summary}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafa91d8-9f99-4057-8221-744bbb82b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/71 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [39:26<00:00, 33.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>aspect</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ю Юлия А. Цвет товара: синий, Российский разме...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>С Сергей Ш. Цвет товара: синий, Российский раз...</td>\n",
       "      <td>negative</td>\n",
       "      <td>quality</td>\n",
       "      <td>Ткань не соответствует ожиданиям</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Цвет товара: серый, Российский размер: 50, Раз...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ф Флера М. Цвет товара: белый, Российский разм...</td>\n",
       "      <td>positive</td>\n",
       "      <td>quality</td>\n",
       "      <td>Худи хорошего качества</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>С Сергей Т. изменен Цвет товара: черный, Росси...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment   aspect  \\\n",
       "0  Ю Юлия А. Цвет товара: синий, Российский разме...   neutral    other   \n",
       "1  С Сергей Ш. Цвет товара: синий, Российский раз...  negative  quality   \n",
       "2  Цвет товара: серый, Российский размер: 50, Раз...   neutral    other   \n",
       "3  Ф Флера М. Цвет товара: белый, Российский разм...  positive  quality   \n",
       "4  С Сергей Т. изменен Цвет товара: черный, Росси...   neutral    other   \n",
       "\n",
       "                            summary  \n",
       "0                                    \n",
       "1  Ткань не соответствует ожиданиям  \n",
       "2                                    \n",
       "3            Худи хорошего качества  \n",
       "4                                    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "res = df[REVIEW_COLUMN].progress_apply(analyze_review)\n",
    "res_df = pd.json_normalize(res)\n",
    "\n",
    "df[\"sentiment\"] = res_df[\"sentiment\"]\n",
    "df[\"aspect\"] = res_df[\"aspect\"]\n",
    "df[\"summary\"] = res_df[\"summary\"]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70cf39b8-25a5-4704-b21d-fa6959c99132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/reviews_out.xlsx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = os.path.splitext(OUTPUT_PATH)[1].lower()\n",
    "if ext in [\".xlsx\", \".xls\"]:\n",
    "    df.to_excel(OUTPUT_PATH, index=False)\n",
    "else:\n",
    "    df.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "OUTPUT_PATH\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-gpu)",
   "language": "python",
   "name": "nlp-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
